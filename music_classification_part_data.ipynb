{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CHjnlitPgbk"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch as nn\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mr-sarthakgupta/MUSIC-GENRE-CLASSIFICATION/main/music_train.csv\")\n",
        "dt = pd.read_csv(\"https://raw.githubusercontent.com/mr-sarthakgupta/MUSIC-GENRE-CLASSIFICATION/main/music_valid.csv\")\n",
        "\n",
        "train_dummies = pd.get_dummies(df['topic'])\n",
        "valid_dummies = pd.get_dummies(dt['topic'])\n",
        "\n",
        "df_z_scaled = df[['dating','violence','world/life','night/time','shake the audience','family/gospel','romantic','communication','obscene','music','movement/places','light/visual perceptions','family/spiritual','like/girls','sadness','feelings','danceability','loudness','acousticness','instrumentalness','valence','energy','age']].copy()\n",
        "\n",
        "for column in df_z_scaled.columns:\n",
        "\tdf_z_scaled[column] = (df_z_scaled[column] -\n",
        "\t\t\t\t\t\tdf_z_scaled[column].mean()) / df_z_scaled[column].std()\t\n",
        "\n",
        "dt_z_scaled = dt[['dating','violence','world/life','night/time','shake the audience','family/gospel','romantic','communication','obscene','music','movement/places','light/visual perceptions','family/spiritual','like/girls','sadness','feelings','danceability','loudness','acousticness','instrumentalness','valence','energy','age']].copy()\n",
        "\n",
        "for column in dt_z_scaled.columns:\n",
        "\tdt_z_scaled[column] = (dt_z_scaled[column] -\n",
        "\t\t\t\t\t\tdt_z_scaled[column].mean()) / dt_z_scaled[column].std()\t\n",
        "\n",
        "train_data = torch.tensor(pd.concat((df[['genre']], df_z_scaled, train_dummies), axis = 1).values)\n",
        "valid_data = torch.tensor(pd.concat((dt[['genre']], dt_z_scaled, valid_dummies), axis = 1).values)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64)\n"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-rTByNgKW4_",
        "outputId": "200ca144-4f84-4687-a912-f5083dd0e2d7"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "    nn.Linear(31, 20) ,\n",
        "    nn.ReLU() ,\n",
        "    nn.Linear(20, 15) ,\n",
        "    nn.ReLU() ,\n",
        "    nn.Linear(15, 10) ,\n",
        "    nn.ReLU() ,\n",
        "    nn.Linear(10, 8) ,\n",
        "    #nn.ReLU() \n",
        "    #nn.Softmax()\n",
        "    )\n",
        "  #  self.fc1 = nn.Linear(31, 20)\n",
        "  #   self.fc2 = nn.Linear(20, 15)\n",
        "  #   self.fc3 = nn.Linear(15, 10)\n",
        "  #   self.fc4 = nn.Linear(10, 8)\n",
        "\n",
        "  def forward(self, x):\n",
        "  #   x = F.relu(self.fc1(x))\n",
        "  #   x = F.relu(self.fc2(x))\n",
        "  #   x = F.relu(self.fc3(x))\n",
        "  #   x = self.fc4(x)\n",
        "  #   return x\n",
        "    results = self.layers(x)\n",
        "    return results\n",
        "  \n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = NeuralNetwork()\n",
        "print(model)\n",
        "\n",
        "learning_rate = 1e-1\n",
        "batch_size = 64\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=50, threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
        "optimizer.zero_grad()\n",
        "model.zero_grad()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=31, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=15, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=15, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=10, out_features=8, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kazcoAnYBnVf"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, data in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X=torch.tensor(data[:,1:], dtype=torch.float64)\n",
        "        X=X.float()\n",
        "        y=torch.tensor(data[:,0:1], dtype=torch.int64)\n",
        "        y=y.squeeze(1)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #batch+=1\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOZ2IlCYLmHv",
        "outputId": "4100092f-83b1-4f43-8d6a-a6363c804dd3"
      },
      "source": [
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.100148  [    0/ 4498]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.924016  [    0/ 4498]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.785041  [    0/ 4498]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.763921  [    0/ 4498]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.862466  [    0/ 4498]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.762955  [    0/ 4498]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.709993  [    0/ 4498]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.680042  [    0/ 4498]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.809757  [    0/ 4498]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.715756  [    0/ 4498]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.669329  [    0/ 4498]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.761013  [    0/ 4498]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.759129  [    0/ 4498]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.752358  [    0/ 4498]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.678813  [    0/ 4498]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.670821  [    0/ 4498]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.531894  [    0/ 4498]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.653616  [    0/ 4498]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.621578  [    0/ 4498]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.499199  [    0/ 4498]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.542184  [    0/ 4498]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 1.382257  [    0/ 4498]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.395706  [    0/ 4498]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.373473  [    0/ 4498]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.581107  [    0/ 4498]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 1.512202  [    0/ 4498]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 1.587656  [    0/ 4498]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.692322  [    0/ 4498]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 1.442989  [    0/ 4498]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 1.565422  [    0/ 4498]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 1.534552  [    0/ 4498]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 1.679601  [    0/ 4498]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 1.364566  [    0/ 4498]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 1.327854  [    0/ 4498]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 1.675896  [    0/ 4498]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 1.303235  [    0/ 4498]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 1.598016  [    0/ 4498]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 1.318969  [    0/ 4498]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 1.271939  [    0/ 4498]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 1.449983  [    0/ 4498]\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 1.583971  [    0/ 4498]\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 1.285948  [    0/ 4498]\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 1.614144  [    0/ 4498]\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 1.560989  [    0/ 4498]\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.399987  [    0/ 4498]\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 1.456387  [    0/ 4498]\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 1.562278  [    0/ 4498]\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 1.493220  [    0/ 4498]\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 1.493722  [    0/ 4498]\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 1.467678  [    0/ 4498]\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyPdbrlYU0b6"
      },
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            X=torch.tensor(data[:,1:], dtype=torch.float64)\n",
        "            X=X.float()\n",
        "            y=torch.tensor(data[:,0:1], dtype=torch.int64)\n",
        "            y=y.squeeze(1)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J_xSrzwGquS",
        "outputId": "13995111-7a2b-45ae-fe7b-2c01a75e595a"
      },
      "source": [
        "test_loop(valid_loader, model, loss_fn)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 40.9%, Avg loss: 0.023957 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm8VcNc0lCh2",
        "outputId": "9ee73057-60a5-4f2c-9a19-b951a4baa936"
      },
      "source": [
        "dv = pd.read_csv('https://raw.githubusercontent.com/mr-sarthakgupta/MUSIC-GENRE-CLASSIFICATION/main/music_test.csv')\n",
        "\n",
        "test_dummies = pd.get_dummies(dv['topic'])\n",
        "\n",
        "dv_z_scaled = dv[['dating','violence','world/life','night/time','shake the audience','family/gospel','romantic','communication','obscene','music','movement/places','light/visual perceptions','family/spiritual','like/girls','sadness','feelings','danceability','loudness','acousticness','instrumentalness','valence','energy','age']].copy()\n",
        "\n",
        "dv_z_scaled = dv[['dating','violence','world/life','night/time','shake the audience','family/gospel','romantic','communication','obscene','music','movement/places','light/visual perceptions','family/spiritual','like/girls','sadness','feelings','danceability','loudness','acousticness','instrumentalness','valence','energy','age']].copy()\n",
        "\n",
        "for column in dv_z_scaled.columns:\n",
        "\tdv_z_scaled[column] = (dv_z_scaled[column] -\n",
        "\t\t\t\t\t\tdv_z_scaled[column].mean()) / dv_z_scaled[column].std()\t\n",
        "      \n",
        "test_data = torch.tensor(pd.concat(( dv_z_scaled, test_dummies), axis = 1).values)\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size=1546)\n",
        "\n",
        "with torch.no_grad():\n",
        "        for batch, data in enumerate(test_loader):\n",
        "            X=torch.tensor(data[:,0:], dtype=torch.float64)\n",
        "            X=X.float()\n",
        "            pred = model(X)\n",
        "            result = pred.argmax(1)\n",
        "            torch.set_printoptions(profile=\"full\")\n",
        "            print(result)\n",
        "k = pd.DataFrame(result)\n",
        "k.to_csv('result.csv',header=False, index=False)\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 3, 2, 6, 3, 1, 1, 1, 4, 4, 1, 4, 4, 6, 5, 5, 3, 5, 3, 5, 4, 1, 0, 1,\n",
            "        4, 5, 4, 1, 5, 4, 1, 6, 2, 1, 2, 1, 4, 4, 4, 5, 3, 1, 5, 1, 4, 5, 1, 1,\n",
            "        1, 1, 6, 5, 4, 6, 6, 6, 2, 1, 1, 5, 1, 4, 0, 4, 4, 6, 0, 1, 3, 3, 1, 5,\n",
            "        1, 1, 4, 0, 5, 3, 6, 3, 5, 3, 6, 1, 1, 3, 4, 2, 6, 1, 6, 4, 4, 4, 1, 1,\n",
            "        6, 1, 4, 1, 0, 1, 1, 4, 1, 3, 1, 6, 5, 2, 1, 4, 1, 3, 6, 4, 4, 6, 4, 6,\n",
            "        1, 1, 1, 0, 1, 4, 4, 6, 1, 0, 5, 1, 1, 5, 5, 4, 1, 4, 0, 1, 2, 6, 4, 6,\n",
            "        6, 1, 1, 5, 5, 6, 5, 4, 3, 5, 1, 6, 0, 1, 1, 1, 1, 4, 4, 4, 1, 6, 0, 4,\n",
            "        4, 5, 4, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 4, 6, 4, 5, 1, 6, 0, 6, 3,\n",
            "        3, 4, 1, 4, 1, 1, 1, 4, 5, 6, 4, 4, 4, 1, 4, 1, 6, 5, 6, 4, 5, 5, 5, 3,\n",
            "        3, 4, 1, 6, 3, 1, 5, 0, 5, 1, 4, 3, 1, 1, 5, 4, 1, 1, 6, 6, 3, 5, 0, 4,\n",
            "        1, 4, 1, 1, 6, 3, 1, 1, 2, 1, 4, 3, 3, 0, 1, 0, 4, 3, 1, 6, 1, 3, 4, 0,\n",
            "        0, 6, 1, 1, 1, 5, 3, 5, 1, 6, 3, 3, 4, 6, 6, 4, 1, 6, 3, 0, 2, 1, 1, 4,\n",
            "        1, 1, 1, 5, 1, 4, 5, 1, 6, 1, 0, 1, 1, 1, 1, 4, 6, 3, 4, 6, 6, 3, 2, 6,\n",
            "        1, 1, 0, 6, 1, 1, 1, 4, 5, 6, 5, 4, 1, 6, 6, 3, 6, 0, 1, 1, 4, 3, 1, 6,\n",
            "        0, 6, 1, 5, 5, 3, 6, 4, 3, 6, 3, 3, 3, 3, 3, 6, 1, 6, 1, 2, 4, 4, 3, 1,\n",
            "        5, 4, 4, 1, 0, 5, 4, 1, 4, 5, 1, 0, 3, 4, 5, 3, 4, 3, 5, 4, 6, 1, 1, 1,\n",
            "        4, 6, 4, 1, 4, 5, 4, 5, 4, 4, 4, 6, 6, 1, 4, 4, 1, 3, 1, 1, 4, 1, 1, 1,\n",
            "        4, 3, 4, 0, 4, 2, 4, 3, 6, 0, 6, 4, 5, 6, 5, 1, 6, 6, 3, 5, 6, 4, 4, 1,\n",
            "        0, 4, 1, 1, 2, 5, 5, 4, 1, 4, 6, 5, 1, 1, 1, 5, 0, 4, 1, 3, 6, 5, 1, 1,\n",
            "        4, 3, 1, 4, 1, 2, 1, 1, 3, 6, 1, 4, 1, 3, 1, 6, 4, 1, 1, 6, 1, 5, 3, 3,\n",
            "        1, 4, 1, 3, 4, 4, 1, 5, 1, 1, 6, 1, 4, 2, 1, 5, 2, 1, 6, 0, 6, 4, 6, 1,\n",
            "        1, 1, 1, 3, 1, 5, 4, 2, 1, 0, 4, 1, 0, 4, 1, 6, 4, 5, 1, 1, 4, 4, 6, 5,\n",
            "        4, 4, 5, 1, 6, 1, 6, 4, 1, 1, 1, 1, 6, 1, 4, 4, 3, 1, 4, 1, 4, 4, 2, 4,\n",
            "        4, 2, 4, 4, 5, 1, 1, 1, 3, 0, 2, 1, 4, 6, 1, 1, 1, 1, 4, 1, 1, 3, 3, 1,\n",
            "        3, 1, 1, 4, 1, 3, 4, 5, 1, 3, 4, 6, 4, 1, 4, 1, 6, 4, 4, 1, 4, 4, 1, 1,\n",
            "        1, 4, 5, 1, 1, 4, 1, 2, 4, 4, 1, 3, 5, 4, 5, 3, 1, 6, 3, 5, 6, 4, 4, 3,\n",
            "        3, 1, 4, 1, 1, 5, 4, 1, 2, 0, 4, 6, 3, 1, 6, 0, 6, 1, 1, 1, 1, 3, 4, 0,\n",
            "        1, 4, 5, 4, 3, 3, 6, 4, 5, 3, 3, 5, 6, 0, 2, 6, 1, 3, 5, 5, 1, 6, 3, 5,\n",
            "        5, 1, 4, 0, 1, 1, 1, 0, 1, 0, 4, 1, 4, 1, 4, 1, 1, 5, 0, 6, 6, 6, 6, 4,\n",
            "        2, 3, 4, 4, 3, 1, 3, 4, 1, 5, 3, 1, 3, 2, 5, 1, 2, 1, 5, 4, 4, 6, 4, 5,\n",
            "        5, 1, 6, 1, 4, 6, 5, 5, 4, 1, 1, 2, 6, 6, 4, 2, 1, 6, 6, 5, 6, 0, 0, 0,\n",
            "        4, 1, 3, 6, 1, 1, 4, 2, 1, 4, 5, 4, 4, 6, 1, 1, 1, 0, 6, 0, 2, 5, 5, 4,\n",
            "        4, 3, 4, 4, 3, 4, 1, 6, 5, 4, 1, 1, 1, 4, 1, 5, 5, 5, 4, 6, 1, 1, 1, 1,\n",
            "        6, 3, 4, 4, 4, 3, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 0, 4, 5, 6, 1, 6, 5,\n",
            "        1, 3, 1, 1, 1, 1, 5, 1, 1, 6, 4, 1, 4, 4, 3, 4, 4, 4, 1, 1, 4, 4, 4, 4,\n",
            "        0, 5, 4, 1, 5, 4, 6, 1, 0, 4, 5, 1, 3, 4, 1, 1, 1, 5, 2, 0, 1, 3, 1, 6,\n",
            "        4, 4, 3, 2, 1, 0, 1, 3, 5, 1, 1, 4, 5, 5, 6, 6, 1, 0, 6, 4, 1, 0, 1, 1,\n",
            "        1, 4, 1, 1, 4, 2, 6, 5, 1, 6, 6, 1, 4, 1, 1, 1, 5, 4, 6, 4, 6, 4, 6, 4,\n",
            "        6, 4, 6, 3, 2, 4, 1, 4, 4, 3, 0, 3, 1, 6, 1, 0, 6, 1, 6, 1, 3, 4, 5, 4,\n",
            "        4, 6, 4, 2, 3, 3, 0, 5, 2, 1, 1, 2, 5, 5, 5, 4, 4, 6, 1, 5, 1, 3, 1, 0,\n",
            "        4, 6, 1, 6, 1, 1, 4, 6, 1, 2, 4, 1, 0, 1, 5, 1, 1, 0, 1, 1, 5, 5, 0, 3,\n",
            "        3, 1, 3, 1, 1, 3, 6, 6, 4, 4, 4, 2, 4, 0, 1, 5, 1, 2, 1, 6, 6, 4, 3, 2,\n",
            "        4, 1, 0, 1, 1, 5, 4, 6, 4, 1, 4, 4, 6, 5, 1, 4, 1, 6, 0, 6, 3, 5, 3, 4,\n",
            "        4, 6, 5, 6, 1, 5, 1, 5, 6, 5, 1, 2, 1, 4, 2, 4, 3, 1, 4, 4, 4, 1, 1, 4,\n",
            "        2, 4, 3, 1, 3, 6, 5, 1, 6, 5, 1, 1, 1, 1, 1, 1, 6, 1, 5, 1, 5, 6, 6, 0,\n",
            "        2, 1, 0, 4, 3, 0, 1, 1, 6, 5, 1, 5, 5, 2, 1, 1, 4, 1, 4, 0, 1, 2, 5, 1,\n",
            "        4, 1, 1, 4, 5, 3, 4, 3, 3, 1, 3, 1, 5, 6, 6, 1, 5, 6, 1, 3, 1, 1, 1, 4,\n",
            "        1, 1, 5, 6, 1, 4, 5, 6, 5, 5, 2, 1, 1, 6, 6, 6, 1, 1, 4, 4, 4, 1, 3, 1,\n",
            "        4, 3, 5, 2, 4, 3, 2, 6, 6, 1, 1, 5, 4, 6, 1, 4, 2, 1, 4, 1, 1, 4, 1, 1,\n",
            "        4, 4, 1, 4, 1, 1, 4, 4, 5, 1, 1, 4, 6, 4, 0, 0, 0, 6, 1, 6, 6, 1, 4, 1,\n",
            "        6, 6, 4, 1, 5, 4, 1, 1, 1, 6, 4, 0, 3, 1, 3, 6, 6, 1, 5, 5, 1, 2, 1, 1,\n",
            "        6, 4, 5, 4, 1, 4, 3, 1, 1, 5, 1, 0, 3, 4, 5, 1, 0, 1, 1, 3, 6, 4, 4, 1,\n",
            "        4, 1, 1, 6, 4, 1, 1, 4, 1, 4, 1, 1, 5, 1, 4, 0, 4, 3, 4, 4, 4, 3, 3, 1,\n",
            "        6, 0, 4, 6, 4, 5, 4, 1, 4, 6, 1, 1, 1, 4, 4, 3, 3, 1, 4, 4, 4, 1, 4, 5,\n",
            "        1, 6, 0, 4, 6, 6, 1, 3, 5, 5, 1, 4, 1, 5, 4, 3, 1, 3, 3, 0, 5, 4, 3, 6,\n",
            "        4, 4, 5, 4, 0, 1, 1, 2, 5, 1, 5, 1, 5, 1, 1, 1, 4, 0, 5, 1, 1, 6, 1, 5,\n",
            "        1, 4, 5, 4, 4, 1, 3, 3, 1, 3, 1, 1, 1, 1, 4, 4, 5, 1, 1, 1, 1, 6, 4, 1,\n",
            "        5, 1, 4, 4, 5, 5, 5, 3, 5, 6, 1, 3, 6, 3, 1, 1, 1, 4, 1, 5, 4, 1, 1, 1,\n",
            "        5, 4, 4, 2, 6, 3, 1, 1, 4, 4, 4, 1, 1, 0, 5, 6, 5, 0, 4, 4, 5, 3, 4, 2,\n",
            "        4, 1, 4, 3, 3, 3, 2, 2, 1, 0, 1, 4, 5, 4, 6, 5, 1, 6, 1, 5, 1, 4, 2, 6,\n",
            "        3, 4, 6, 1, 1, 1, 1, 2, 5, 1, 5, 5, 4, 1, 1, 1, 6, 6, 1, 1, 1, 4, 3, 1,\n",
            "        1, 6, 5, 4, 6, 1, 4, 5, 4, 1, 1, 4, 2, 5, 1, 4, 4, 5, 6, 3, 3, 0, 4, 4,\n",
            "        1, 1, 1, 4, 1, 1, 3, 5, 5, 1, 1, 6, 1, 4, 4, 0, 5, 2, 1, 2, 4, 6, 4, 4,\n",
            "        2, 3, 6, 6, 2, 4, 4, 5, 4, 4, 0, 6, 2, 1, 6, 4, 3, 6, 1, 4, 4, 6, 0, 1,\n",
            "        6, 5, 3, 1, 1, 1, 3, 1, 6, 6])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge8hFrfU6uyZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}